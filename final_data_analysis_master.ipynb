{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final Data Analysis Notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hashtag Popularity "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'config'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-b8e095b0d049>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[1;31m# Twitter API Keys\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 16\u001b[1;33m from config import (consumer_key, \n\u001b[0m\u001b[0;32m     17\u001b[0m                     \u001b[0mconsumer_secret\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m                     \u001b[0maccess_token\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'config'"
     ]
    }
   ],
   "source": [
    "import tweepy\n",
    "import random\n",
    "import time\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "\n",
    "from pprint import pprint\n",
    "from collections import Counter\n",
    "\n",
    "# Twitter API Keys\n",
    "from config import (consumer_key, \n",
    "                    consumer_secret, \n",
    "                    access_token, \n",
    "                    access_token_secret)\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "analyzer = SentimentIntensityAnalyzer()\n",
    "\n",
    "# Setup Tweepy API Authentication\n",
    "auth = tweepy.OAuthHandler(consumer_key, consumer_secret)\n",
    "auth.set_access_token(access_token, access_token_secret)\n",
    "api = tweepy.API(auth, parser=tweepy.parsers.JSONParser())\n",
    "\n",
    "#########\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = 'merged_lists_032118.csv'\n",
    "df_merged = pd.read_csv(file)\n",
    "df_merged.head()\n",
    "\n",
    "###########################\n",
    "\n",
    "target_users = df_merged['fitness_users'].tolist()\n",
    "\n",
    "users = []\n",
    "textlist = []\n",
    "tweetdates = []\n",
    "\n",
    "randomusers = random.sample(target_users, 100)\n",
    "\n",
    "for target in randomusers:\n",
    "    \n",
    "    print(f\"Getting tweets of {target}\")\n",
    "            \n",
    "    for x in range(1):        \n",
    "        try:\n",
    "            public_tweets = api.user_timeline(target, count=100)\n",
    "       \n",
    "        # Loop through all tweets\n",
    "            for tweet in public_tweets:\n",
    "\n",
    "                text = tweet['text']\n",
    "                textlist.append(text)\n",
    "                users.append(target)\n",
    "                date = tweet[\"created_at\"]\n",
    "                tweetdates.append(date)\n",
    "        except tweepy.error.TweepError:\n",
    "            print(f\"{target} skipped\")\n",
    "        continue\n",
    "    time.sleep(10)\n",
    "    \n",
    "###################################\n",
    "hashtag_data = pd.DataFrame({\"CreateDate\":tweetdates, \"Tweet\": textlist, \"User\":users})\n",
    "hashtag_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hashtag_data.to_csv('hashtag_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nopainnogain = 0\n",
    "cardio = 0\n",
    "cycling = 0\n",
    "fitspo = 0\n",
    "exercise = 0\n",
    "gym = 0\n",
    "fitfam = 0\n",
    "fitlife = 0\n",
    "fitness = 0\n",
    "fitnessaddict = 0\n",
    "gymlife = 0\n",
    "gymrat = 0\n",
    "gymtime = 0\n",
    "marathon = 0\n",
    "workout = 0\n",
    "runners = 0\n",
    "fit = 0\n",
    "GetFit = 0\n",
    "motivation = 0\n",
    "justdoit = 0\n",
    "TrainHard = 0\n",
    "bodybuilding = 0\n",
    "\n",
    "for row in hashtag_data['Tweet']:\n",
    "    if '#NoPainNoGain' in row:\n",
    "        nopainnogain +=1\n",
    "    elif '#Cardio' in row:\n",
    "        cardio +=1\n",
    "    elif '#cardio' in row:\n",
    "        cardio +=1\n",
    "    elif '#cycling' in row:\n",
    "        cycling +=1\n",
    "    elif '#fitspo' in row:\n",
    "        fitspo +=1\n",
    "    elif '#exercise' in row:\n",
    "        exercise +=1\n",
    "    elif '#Exercise' in row:\n",
    "        exercise +=1\n",
    "    elif '#gym' in row:\n",
    "        gym +=1\n",
    "    elif '#fitfam' in row:\n",
    "        fitfam +=1\n",
    "    elif '#FitFam' in row:\n",
    "        fitfam +=1\n",
    "    elif '#fitlife' in row:\n",
    "        fitlife +=1\n",
    "    elif '#FitLife' in row:\n",
    "        fitlife +=1\n",
    "    elif '#fitness' in row:\n",
    "        fitness +=1\n",
    "    elif '#Fitness' in row:\n",
    "        fitness +=1\n",
    "    elif '#fitnessaddict' in row:\n",
    "        fitnessaddict +=1\n",
    "    elif '#FitnessAddict' in row:\n",
    "        fitnessaddict +=1\n",
    "    elif '#gymlife' in row:\n",
    "        gymlife +=1\n",
    "    elif '#GymLife' in row:\n",
    "        gymlife +=1\n",
    "    elif '#gymrat' in row:\n",
    "        gymrat +=1\n",
    "    elif '#gymtime' in row:\n",
    "        gymtime +=1\n",
    "    elif '#GymTime' in row:\n",
    "        gymtime +=1\n",
    "    elif '#marathon' in row:\n",
    "        marathon +=1\n",
    "    elif '#Marathon' in row:\n",
    "        marathon +=1\n",
    "    elif '#workout' in row:\n",
    "        workout +=1\n",
    "    elif '#Workout' in row:\n",
    "        workout +=1\n",
    "    elif '#runners' in row:\n",
    "        runners +=1\n",
    "    elif '#Runners' in row:\n",
    "        runners +=1\n",
    "    elif '#fit' in row:\n",
    "        fit +=1\n",
    "    elif '#Fit' in row:\n",
    "        fit +=1\n",
    "    elif '#GetFit' in row:\n",
    "        GetFit +=1\n",
    "    elif '#motivation' in row:\n",
    "        motivation +=1\n",
    "    elif '#Motivation' in row:\n",
    "        motivation +=1\n",
    "    elif '#justdoit' in row:\n",
    "        justdoit +=1\n",
    "    elif '#JustDoIt' in row:\n",
    "        justdoit +=1\n",
    "    elif '#TrainHard' in row:\n",
    "        TrainHard +=1\n",
    "    elif '#bodybuilding' in row:\n",
    "        bodybuilding +=1    \n",
    "\n",
    "fitness_hashtags = [\"#nopainnogain\",\"#cardio\",\"#cycling\",\"#fitspo\",\"#exercise\",\n",
    "                    \"#gym\",\"#fitfam\",\"#fitlife\",\"#fitness\",\"#fitnessaddict\",\"#gymlife\",\n",
    "                    \"#gymrat\",\"#gymtime\",\"#marathon\",\"#workout\",\"#runners\",\"#fit\",\"#GetFit\",\n",
    "                    \"#motivation\",\"#justdoit\",\"#TrainHard\",\"#bodybuilding\"]\n",
    "\n",
    "fitness_hashtag_counts = [nopainnogain,cardio,cycling,fitspo,exercise,\n",
    "                          gym,fitfam,fitlife,fitness,fitnessaddict,gymlife,\n",
    "                          gymrat, gymtime,marathon,workout,runners,fit,GetFit,\n",
    "                          motivation,justdoit,TrainHard,bodybuilding]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_hashtag = pd.DataFrame({'Count':fitness_hashtag_counts,'Hashtag':fitness_hashtags})\n",
    "sorted_hashtag_df = pd.DataFrame(df_hashtag.sort_values('Count',ascending=False))\n",
    "sorted_hashtag_df\n",
    "# TICK LOCATION ADD - ROTATION to HASHTAGS - SORT HASHTAGS by POPULARITY\n",
    "\n",
    "# plt.figure(figsize=(18,10))\n",
    "# plt.bar(fitness_hashtags, fitness_hashtag_counts, color='b', alpha=0.5, align=\"edge\")\n",
    "# plt.xticks(rotation=45)\n",
    "# plt.xlabel(\"Hashtags\",fontsize =12)\n",
    "# plt.ylabel(\"Number of Hashtags\",fontsize =14)\n",
    "# plt.title(\"Fitness Hashtags Popularity for Fitness Users\",fontsize =14)\n",
    "# plt.savefig(\"FitnessHashtagPopularity.png\")\n",
    "# plt.show()\n",
    "\n",
    "x_axis = np.arange(len(sorted_hashtag_df['Hashtag']))\n",
    "plt.figure(figsize=(18,8))\n",
    "plt.bar(x_axis, sorted_hashtag_df['Count'], color='b', alpha=0.5, align=\"edge\")\n",
    "tick_locations = [value+0.4 for value in x_axis]\n",
    "plt.xticks(tick_locations, sorted_hashtag_df['Hashtag'], rotation=45)\n",
    "plt.xlabel(\"Hashtags\",fontsize =14)\n",
    "plt.ylabel(\"Number of Hashtags\",fontsize =14)\n",
    "plt.title(\"Fitness Hashtags Popularity for Fitness Users\",fontsize =14)\n",
    "plt.savefig(\"FitnessHashtagPopularity.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gym_df = pd.DataFrame(hashtag_data[hashtag_data['Tweet'].str.contains('#gym')])\n",
    "gym_df.reset_index(inplace=True)\n",
    "\n",
    "motivation_df = pd.DataFrame(hashtag_data[hashtag_data['Tweet'].str.contains('#motivation|#Motivation')])\n",
    "motivation_df.reset_index(inplace=True)\n",
    "\n",
    "fitness_df = pd.DataFrame(hashtag_data[hashtag_data['Tweet'].str.contains('#fitness|#Fitness')])\n",
    "fitness_df.reset_index(inplace=True)\n",
    "\n",
    "fitfam_df= pd.DataFrame(hashtag_data[hashtag_data['Tweet'].str.contains('#fitfam|#FitFam')])\n",
    "fitfam_df.reset_index(inplace=True)\n",
    "\n",
    "justdoit_df = pd.DataFrame(hashtag_data[hashtag_data['Tweet'].str.contains('#justdoit|#JustDoIt')])\n",
    "justdoit_df.reset_index(inplace=True)\n",
    "\n",
    "fitspo_df = pd.DataFrame(hashtag_data[hashtag_data['Tweet'].str.contains('#fitspo|#Fitspo')])\n",
    "fitspo_df.reset_index(inplace=True)\n",
    "\n",
    "fitlife_df = pd.DataFrame(hashtag_data[hashtag_data['Tweet'].str.contains('#fitlife|#FitLife')])\n",
    "fitspo_df.reset_index(inplace=True)\n",
    "\n",
    "fit_df = pd.DataFrame(hashtag_data[hashtag_data['Tweet'].str.contains('#fit|#Fit')])\n",
    "fit_df.reset_index(inplace=True)\n",
    "\n",
    "cycling_df = pd.DataFrame(hashtag_data[hashtag_data['Tweet'].str.contains('#cycling')])\n",
    "cycling_df.reset_index(inplace=True)\n",
    "\n",
    "workout_df = pd.DataFrame(hashtag_data[hashtag_data['Tweet'].str.contains('#workout|#Workout')])\n",
    "workout_df.reset_index(inplace=True)\n",
    "\n",
    "cardio_df = pd.DataFrame(hashtag_data[hashtag_data['Tweet'].str.contains('#cardio|#Cardio')])\n",
    "cardio_df.reset_index(inplace=True)\n",
    "\n",
    "exercise_df = pd.DataFrame(hashtag_data[hashtag_data['Tweet'].str.contains('#exercise|#Exercise')])\n",
    "exercise_df.reset_index(inplace=True)\n",
    "\n",
    "bodybuilding_df = pd.DataFrame(hashtag_data[hashtag_data['Tweet'].str.contains('#bodybuilding')])\n",
    "bodybuilding_df.reset_index(inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compound_list=[]\n",
    "positive_list=[]\n",
    "negative_list=[]\n",
    "neutral_list=[]\n",
    "\n",
    "for row in justdoit_df['Tweet']:\n",
    "\n",
    "    # Run Vader Analysis on each tweet\n",
    "    results = analyzer.polarity_scores(row)\n",
    "    compound = results[\"compound\"]\n",
    "    pos = results[\"pos\"]\n",
    "    neu = results[\"neu\"]\n",
    "    neg = results[\"neg\"]\n",
    "\n",
    "    # Add each value to the appropriate array\n",
    "    compound_list.append(compound)\n",
    "    positive_list.append(pos)\n",
    "    negative_list.append(neg)\n",
    "    neutral_list.append(neu)\n",
    "\n",
    "# Store the Average Sentiments\n",
    "sentiment_nopainnogain= {\n",
    "    \"Hashtag\":'#nopainnogain',\n",
    "    \"Compound\": np.mean(compound_list),\n",
    "}\n",
    "\n",
    "\n",
    "d = [sentiment_gym,sentiment_motivation,sentiment_fitness,sentiment_fitfam,sentiment_justdoit,sentiment_fitspo,\n",
    " sentiment_fitlife, sentiment_fit, sentiment_cycling, sentiment_workout,sentiment_cardio, \n",
    " sentiment_exercise, sentiment_bodybuilding ]\n",
    "Hashtag_Sentiment_df = pd.DataFrame(d)\n",
    "Hashtag_Sentiment_df\n",
    "#####################################\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_axis = np.arange(len(Hashtag_Sentiment_df['Hashtag']))\n",
    "plt.figure(figsize=(10,7))\n",
    "plt.bar(x_axis, Hashtag_Sentiment_df['Compound'], color='r', alpha=0.5, align=\"edge\")\n",
    "tick_locations = [value+0.4 for value in x_axis]\n",
    "plt.xticks(tick_locations, Hashtag_Sentiment_df['Hashtag'], rotation=45)\n",
    "plt.xlabel(\"Hashtags\",fontsize=12)\n",
    "plt.ylabel(\"Compounds\",fontsize=12)\n",
    "plt.title(\"Sentiment Compounds of Tweets w/Fitness Hashtags\",fontsize=14)\n",
    "plt.savefig(\"SentimentAnalysisHashtags.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fitness/Eating "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dependencies\n",
    "import random\n",
    "import time\n",
    "import pandas as pd\n",
    "import tweepy\n",
    "import json\n",
    "import numpy as np\n",
    "from pprint import pprint\n",
    "from datetime import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "from config import consumer_key, consumer_secret, access_token, access_token_secret\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "analyzer = SentimentIntensityAnalyzer()\n",
    "\n",
    "# Setup Tweepy API Authentication\n",
    "auth = tweepy.OAuthHandler(consumer_key, consumer_secret)\n",
    "auth.set_access_token(access_token, access_token_secret)\n",
    "api = tweepy.API(auth, parser=tweepy.parsers.JSONParser())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pull in user account data\n",
    "users_file = \"merged_lists_032118.csv\"\n",
    "\n",
    "users_df = pd.read_csv(users_file)\n",
    "users_df.head()\n",
    "fitness_users = users_df[\"fitness_users\"]\n",
    "normal_users = users_df[\"normal_users\"]\n",
    "normal_users\n",
    "\n",
    "#######################\n",
    "\n",
    "# Separate out fitness users to loop through and search their usage of healthy eating hashtags\n",
    "fitness_users = users_df[\"fitness_users\"]\n",
    "\n",
    "# Target Healthy Eating Hashtags\n",
    "target_tags = [\"#EatClean\", \"#EatLocal\", \"#FitFood\", \"#GlutenFree\",\n",
    "                \"#HealthyEating\", \"#HealthyRecipes\", \"#Nutrition\",\n",
    "              \"#protein\", \"#cleaneating\", \"#fitnessfood\", \"#diet\", \"#plantbased\"]\n",
    "\n",
    "fitness_user_accounts = {}\n",
    "\n",
    "# Loop through the each of the users\n",
    "for user in fitness_users:\n",
    "\n",
    "    # Get all tweets from home feed\n",
    "    try:\n",
    "        public_tweets = api.user_timeline(user, count=100)\n",
    "    except tweepy.error.TweepError:\n",
    "        print(f\"Cannot get the data for {user}. Skipping\")\n",
    "        continue\n",
    "    \n",
    "    print(f\"Working on getting data for {user}.\")\n",
    "    \n",
    "    # Add screen name to user list\n",
    "    if(user not in fitness_user_accounts):\n",
    "        fitness_user_accounts[user] = 1\n",
    "            \n",
    "    # Loop through all tweets\n",
    "    for tweet in public_tweets:\n",
    "\n",
    "        # Check to see if the tweets contain the fitness words\n",
    "        if \"#eatclean\" in tweet[\"text\"]:\n",
    "            fitness_user_accounts[user] += 1\n",
    "        elif \"#eatlocal\" in tweet[\"text\"]:\n",
    "            fitness_user_accounts[user] += 1\n",
    "        elif \"#fitfood\" in tweet[\"text\"]:\n",
    "            fitness_user_accounts[user] += 1\n",
    "        elif \"#glutenfree\" in tweet[\"text\"]:\n",
    "            fitness_user_accounts[user] += 1\n",
    "        elif \"#healthyeating\" in tweet[\"text\"]:\n",
    "            fitness_user_accounts[user] += 1\n",
    "        elif \"#healthyrecipes\" in tweet[\"text\"]:\n",
    "            fitness_user_accounts[user] += 1\n",
    "        elif \"#nutrition\" in tweet[\"text\"]:\n",
    "            fitness_user_accounts[user] += 1\n",
    "        elif \"#protein\" in tweet[\"text\"]:\n",
    "            fitness_user_accounts[user] += 1\n",
    "        elif \"#plantbased\" in tweet[\"text\"]:\n",
    "            fitness_user_accounts[user] += 1\n",
    "        elif \"#diet\" in tweet[\"text\"]:\n",
    "            fitness_user_accounts[user] += 1\n",
    "        elif \"#cleaneating\" in tweet[\"text\"]:\n",
    "            fitness_user_accounts[user] += 1\n",
    "        elif \"fitnessfood\" in tweet[\"text\"]:\n",
    "            fitness_user_accounts[user] += 1\n",
    "        \n",
    "    # Set to sleep to avoid surpassing API rate limits\n",
    "    time.sleep(15)\n",
    "    \n",
    "# View         \n",
    "print(fitness_user_accounts)\n",
    "\n",
    "#####################################\n",
    "fitness_user_accounts_pd = pd.Series(fitness_user_accounts)\n",
    "\n",
    "fitness_user_accounts_pd.sort_values(ascending=False)\n",
    "\n",
    "#######################################\n",
    "\n",
    "# TEST #\n",
    "\n",
    "test_fitness_users = [\"SupraSonicIrish\"]\n",
    "test_fitness_user_accounts = {}\n",
    "\n",
    "# Loop through the each of the users\n",
    "for user in test_fitness_users:\n",
    "\n",
    "    # Get all tweets from home feed\n",
    "    try:\n",
    "        public_tweets = api.user_timeline(user, count=100)\n",
    "    except tweepy.error.TweepError:\n",
    "        print(f\"Cannot get the data for {user}. Skipping\")\n",
    "        continue\n",
    "    \n",
    "    print(f\"Working on getting data for {user}.\")\n",
    "    \n",
    "    # Add screen name to user list\n",
    "    if(user not in test_fitness_user_accounts):\n",
    "        test_fitness_user_accounts[user] = 1\n",
    "            \n",
    "    # Loop through all tweets\n",
    "    for tweet in public_tweets:\n",
    "        print(tweet[\"text\"])\n",
    "\n",
    "        # Check to see if the tweets contain the fitness words\n",
    "        if \"#eatclean\" in tweet[\"text\"]:\n",
    "            test_fitness_user_accounts[user] += 1\n",
    "        elif \"#eatlocal\" in tweet[\"text\"]:\n",
    "            test_fitness_user_accounts[user] += 1\n",
    "        elif \"#fitfood\" in tweet[\"text\"]:\n",
    "            test_fitness_user_accounts[user] += 1\n",
    "        elif \"#glutenfree\" in tweet[\"text\"]:\n",
    "            test_fitness_user_accounts[user] += 1\n",
    "        elif \"#healthyeating\" in tweet[\"text\"]:\n",
    "            test_fitness_user_accounts[user] += 1\n",
    "        elif \"#healthyrecipes\" in tweet[\"text\"]:\n",
    "            test_fitness_user_accounts[user] += 1\n",
    "        elif \"#nutrition\" in tweet[\"text\"]:\n",
    "            test_fitness_user_accounts[user] += 1\n",
    "        elif \"#protein\" in tweet[\"text\"]:\n",
    "            test_fitness_user_accounts[user] += 1\n",
    "        elif \"#plantbased\" in tweet[\"text\"]:\n",
    "            test_fitness_user_accounts[user] += 1\n",
    "        elif \"#diet\" in tweet[\"text\"]:\n",
    "            test_fitness_user_accounts[user] += 1\n",
    "        elif \"#cleaneating\" in tweet[\"text\"]:\n",
    "            test_fitness_user_accounts[user] += 1\n",
    "        elif \"fitnessfood\" in tweet[\"text\"]:\n",
    "            test_fitness_user_accounts[user] += 1\n",
    "        \n",
    "    # Set to sleep to avoid surpassing API rate limits\n",
    "    time.sleep(15)\n",
    "    \n",
    "# View         \n",
    "print(test_fitness_user_accounts)\n",
    "\n",
    "###################################################\n",
    "\n",
    "# Separate out normal users to loop through and search their usage of healthy eating hashtags\n",
    "normal_users = users_df[\"normal_users\"]\n",
    "\n",
    "# Create an empty array to hold the data\n",
    "\n",
    "normal_user_accounts = {}\n",
    "user_num = 0\n",
    "\n",
    "# Loop through the each of the users\n",
    "for user in normal_users:\n",
    "    \n",
    "    # Add a number to user_num to track the progress\n",
    "    user_num += 1\n",
    "\n",
    "    # Get all tweets from home feed\n",
    "    try:\n",
    "        public_tweets = api.user_timeline(user, count=100)\n",
    "    except tweepy.error.TweepError:\n",
    "        print(f\"Cannot get the data for {user}. Skipping\")\n",
    "        continue\n",
    "    \n",
    "    print(f\"Working on getting data for {user} who is {user_num}.\")\n",
    "    \n",
    "    # Add screen name to user list\n",
    "    if(user not in normal_user_accounts):\n",
    "        normal_user_accounts[user] = 1\n",
    "            \n",
    "    # Loop through all tweets\n",
    "    for tweet in public_tweets:\n",
    "\n",
    "        # Check to see if the tweets contain the fitness words\n",
    "        if \"#eatclean\" in tweet[\"text\"]:\n",
    "            normal_user_accounts[user] += 1\n",
    "        elif \"#eatlocal\" in tweet[\"text\"]:\n",
    "            normal_user_accounts[user] += 1\n",
    "        elif \"#fitfood\" in tweet[\"text\"]:\n",
    "            normal_user_accounts[user] += 1\n",
    "        elif \"#glutenfree\" in tweet[\"text\"]:\n",
    "            normal_user_accounts[user] += 1\n",
    "        elif \"#healthyeating\" in tweet[\"text\"]:\n",
    "            normal_user_accounts[user] += 1\n",
    "        elif \"#healthyrecipes\" in tweet[\"text\"]:\n",
    "            normal_user_accounts[user] += 1\n",
    "        elif \"#nutrition\" in tweet[\"text\"]:\n",
    "            normal_user_accounts[user] += 1\n",
    "        elif \"#protein\" in tweet[\"text\"]:\n",
    "            normal_user_accounts[user] += 1\n",
    "        elif \"#plantbased\" in tweet[\"text\"]:\n",
    "            normal_user_accounts[user] += 1\n",
    "        elif \"#diet\" in tweet[\"text\"]:\n",
    "            normal_user_accounts[user] += 1\n",
    "        elif \"#cleaneating\" in tweet[\"text\"]:\n",
    "            normal_user_accounts[user] += 1\n",
    "        elif \"fitnessfood\" in tweet[\"text\"]:\n",
    "            normal_user_accounts[user] += 1\n",
    "    \n",
    "    \n",
    "    # Set to sleep to avoid surpassing API rate limits\n",
    "    time.sleep(20)\n",
    "    \n",
    "# View         \n",
    "print(normal_user_accounts)\n",
    "\n",
    "##########################################\n",
    "normal_user_accounts_pd = pd.Series(normal_user_accounts)\n",
    "\n",
    "normal_user_accounts_pd.sort_values(ascending=False)\n",
    "\n",
    "##########################################\n",
    "# Adjust arrays to reflect that I started all usernames with 1\n",
    "\n",
    "fitness_user_accounts_pd = fitness_user_accounts_pd + 1\n",
    "normal_user_accounts_pd = normal_user_accounts_pd + 1\n",
    "\n",
    "fitness_user_accounts_pd\n",
    "normal_user_accounts_pd\n",
    "#########################################\n",
    "# Find the means for each group\n",
    "normal_mean = np.mean(normal_user_accounts_pd)\n",
    "fitness_mean = np.mean(fitness_user_accounts_pd)\n",
    "fitness_mean\n",
    "normal_mean\n",
    "#########################################\n",
    "\n",
    "# Plot the results\n",
    "\n",
    "means = [fitness_mean, normal_mean]\n",
    "\n",
    "users = [\"Fitness\", \"Normal\"]\n",
    "x_axis = np.arange(len(users))\n",
    "\n",
    "plt.bar(x_axis, means, color='g', alpha=0.5, align=\"edge\")\n",
    "\n",
    "tick_locations = [value+0.4 for value in x_axis]\n",
    "plt.xticks(tick_locations, [\"Fitness\", \"Normal\"])\n",
    "plt.xlabel(\"User Groups\")\n",
    "plt.ylabel(\"Mean of hashtags per 100 tweets\")\n",
    "plt.title(\"Mean of Healthy Eating Hashtags over 500 Users\")\n",
    "plt.savefig(\"fitness_normal.png\")\n",
    "\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fitness_user_accounts_pd.to_csv(\"fitness_eating_tags.csv\", encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eating_file = \"fitness_eating_tags.csv\"\n",
    "\n",
    "eating_df = pd.read_csv(eating_file)\n",
    "eating_df\n",
    "\n",
    "# Plot the hashtag info for fitness users\n",
    "x_axis = np.arange(len(eating_df['Account']))\n",
    "x_axis\n",
    "plt.figure(figsize=(20,10))\n",
    "plt.bar(x_axis, eating_df['Count'], color='g', alpha=0.5, align=\"edge\")\n",
    "\n",
    "tick_locations = [value+0.4 for value in x_axis]\n",
    "plt.xticks(tick_locations, eating_df['Account'], rotation=90)\n",
    "plt.xlabel(\"Fitness Accounts with Healhty Eating Hashtags\")\n",
    "plt.ylabel(\"Count of Hashtags Used Over 100 Tweets\")\n",
    "plt.title(\"Frequency of Healthy Eating Hashtags Used by Fitness Users\")\n",
    "plt.savefig(\"healthy_eating_#.png\")\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Average number of healthy eating hastags over last 100 tweets\n",
    "eating_df['Count'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Take out possible outliers\n",
    "eating_df_new = eating_df.loc[eating_df['Count'] < 40]\n",
    "eating_df_new['Count'].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setting up for TTest "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dependencies\n",
    "import tweepy\n",
    "import random\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.stats import sem, ttest_ind\n",
    "\n",
    "# Twitter API Keys\n",
    "from config import (consumer_key, \n",
    "                    consumer_secret, \n",
    "                    access_token, \n",
    "                    access_token_secret)\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "analyzer = SentimentIntensityAnalyzer()\n",
    "\n",
    "# Setup Tweepy API Authentication\n",
    "auth = tweepy.OAuthHandler(consumer_key, consumer_secret)\n",
    "auth.set_access_token(access_token, access_token_secret)\n",
    "api = tweepy.API(auth, parser=tweepy.parsers.JSONParser())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fit_file = \"datasets/fit_tweets.csv\"\n",
    "norm_file = \"datasets/norm_tweets1.csv\"\n",
    "\n",
    "fit_tweets = pd.read_csv(fit_file, encoding='utf-8')\n",
    "norm_tweets = pd.read_csv(norm_file, encoding='utf-8')\n",
    "fit_tweets = fit_tweets.dropna()\n",
    "norm_tweets = norm_tweets.dropna()\n",
    "if len(fit_tweets) < len(norm_tweets):\n",
    "    norm_tweets = norm_tweets.sample(n=len(fit_tweets))\n",
    "else:\n",
    "    fit_tweets = fit_tweets.sample(n=len(norm_tweets))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "norm_acct_groups = norm_tweets.groupby('Account')\n",
    "norm_mean_sents = (norm_acct_groups['Compound'].mean()).tolist()\n",
    "norm_mean_poss = (norm_acct_groups['Positive'].mean()).tolist()\n",
    "norm_mean_neus = (norm_acct_groups['Neutral'].mean()).tolist()\n",
    "norm_mean_negs = (norm_acct_groups['Negative'].mean()).tolist()\n",
    "\n",
    "fit_acct_groups = fit_tweets.groupby('Account')\n",
    "fit_mean_sents = (fit_acct_groups['Compound'].mean()).tolist()\n",
    "fit_mean_poss = (fit_acct_groups['Positive'].mean()).tolist()\n",
    "fit_mean_neus = (fit_acct_groups['Neutral'].mean()).tolist()\n",
    "fit_mean_negs = (fit_acct_groups['Negative'].mean()).tolist()\n",
    "\n",
    "sent_comparison = pd.DataFrame({\n",
    "    'Fitness User':[np.nanmean(fit_mean_sents),np.nanmean(fit_mean_poss),np.nanmean(fit_mean_negs),np.nanmean(fit_mean_neus)],\n",
    "    'Normal User':[np.nanmean(norm_mean_sents),np.nanmean(norm_mean_poss),np.nanmean(norm_mean_negs),np.nanmean(norm_mean_neus)],\n",
    "    'Value':['Compound','Positive','Negative','Neutral']\n",
    "})\n",
    "sent_comparison = sent_comparison.set_index(\"Value\") \n",
    "sent_comparison.to_csv('sent_comparison.csv',encoding='utf-8')\n",
    "sent_comparison   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sented_n_tweets = norm_tweets.loc[norm_tweets['Compound']!=0]\n",
    "sented_f_tweets = fit_tweets.loc[fit_tweets['Compound']!=0]\n",
    "\n",
    "norm_acct_groups = sented_n_tweets.groupby('Account')\n",
    "norm_mean_sents = (norm_acct_groups['Compound'].mean()).tolist()\n",
    "norm_mean_poss = (norm_acct_groups['Positive'].mean()).tolist()\n",
    "norm_mean_neus = (norm_acct_groups['Neutral'].mean()).tolist()\n",
    "norm_mean_negs = (norm_acct_groups['Negative'].mean()).tolist()\n",
    "\n",
    "fit_acct_groups = sented_f_tweets.groupby('Account')\n",
    "fit_mean_sents = (fit_acct_groups['Compound'].mean()).tolist()\n",
    "fit_mean_poss = (fit_acct_groups['Positive'].mean()).tolist()\n",
    "fit_mean_neus = (fit_acct_groups['Neutral'].mean()).tolist()\n",
    "fit_mean_negs = (fit_acct_groups['Negative'].mean()).tolist()\n",
    "\n",
    "sented_comparison = pd.DataFrame({\n",
    "    'Fitness User':[np.nanmean(fit_mean_sents),np.nanmean(fit_mean_poss),np.nanmean(fit_mean_negs),np.nanmean(fit_mean_neus)],\n",
    "    'Normal User':[np.nanmean(norm_mean_sents),np.nanmean(norm_mean_poss),np.nanmean(norm_mean_negs),np.nanmean(norm_mean_neus)],\n",
    "    'Value':['Compound','Positive','Negative','Neutral']\n",
    "})\n",
    "sented_comparison = sented_comparison.set_index(\"Value\") \n",
    "sented_comparison.to_csv('sent_comparison_drop_neu.csv',encoding='utf-8')\n",
    "sented_comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "probs = []\n",
    "t_vals = []\n",
    "sented_n_groups = sented_n_tweets.groupby('Account')\n",
    "norm_mean_sents = (sented_n_groups['Compound'].mean()).tolist()\n",
    "sented_f_groups = sented_f_tweets.groupby('Account')\n",
    "fit_mean_sents = (sented_f_groups['Compound'].mean()).tolist()\n",
    "(ttest,p) = ttest_ind(norm_mean_sents,fit_mean_sents,equal_var=True)\n",
    "probs.append(p)\n",
    "t_vals.append(ttest)\n",
    "\n",
    "neu_n_groups = norm_tweets.groupby('Account')\n",
    "neu_n_sents = (neu_n_groups['Compound'].mean()).tolist()\n",
    "neu_f_groups = fit_tweets.groupby('Account')\n",
    "neu_f_sents = (neu_f_groups['Compound'].mean()).tolist()\n",
    "(ttest,p) = ttest_ind(neu_n_sents,neu_f_sents,equal_var=True)\n",
    "probs.append(p)\n",
    "t_vals.append(ttest)\n",
    "\n",
    "ttest_summ = pd.DataFrame({\n",
    "    'Neutrals':['N','Y'],\n",
    "    'T-Score':t_vals,\n",
    "    'P-Value':probs,\n",
    "    'Mean Fitness Sent':[sented_comparison.iloc[0,0],sent_comparison.iloc[0,0]],\n",
    "    'Mean Normal Sent':[sented_comparison.iloc[0,1],sent_comparison.iloc[0,1]]\n",
    "})\n",
    "\n",
    "ttest_summ = ttest_summ.set_index('Neutrals')\n",
    "ttest_summ.to_csv('ttest_summary.csv')\n",
    "ttest_summ\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax = plt.subplots()\n",
    "x_axis = np.arange(0,40)\n",
    "for x in range(100):\n",
    "    norm_sample = random.sample(norm_mean_sents,40)\n",
    "    fit_sample = random.sample(fit_mean_sents,40)\n",
    "    ax.scatter(x_axis, norm_sample, color='red',alpha=.5,label='Normal Users')\n",
    "    ax.scatter(x_axis, fit_sample, color='blue',alpha=.5,label='Fitness Users')\n",
    "    \n",
    "plt.xlabel(\"Tweets\")\n",
    "plt.ylabel(\"Polarity Compound\")\n",
    "plt.title(\"Average Sentiment of Fitness(Blue) vs non-Fitness(Red) Tweets\")\n",
    "plt.savefig('user_summary_scatter.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_axis = np.arange(2)\n",
    "tick_labels = ['Fitness Users','Normal Users']\n",
    "fig,ax = plt.subplots()\n",
    "ax.bar(x_axis,sented_comparison.iloc[0,:],label='Without Neutrals')\n",
    "ax.bar(x_axis,sent_comparison.iloc[0,:],color='red',label='Including Neutrals')\n",
    "plt.xticks(x_axis,tick_labels)\n",
    "plt.ylabel('Average Polarity Compound')\n",
    "plt.title('Average Tweet Polarity, Fitness vs. Regular Users')\n",
    "plt.legend()\n",
    "plt.savefig('user_summary_bar.png')\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
