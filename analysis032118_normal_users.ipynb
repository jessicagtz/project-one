{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Dependencies\n",
    "import tweepy\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "from config import consumer_key, consumer_secret, access_token, access_token_secret\n",
    "from pprint import pprint\n",
    "# Import and Initialize Sentiment Analyzer\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "analyzer = SentimentIntensityAnalyzer()\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Setup Tweepy API Authentication\n",
    "auth = tweepy.OAuthHandler(consumer_key, consumer_secret)\n",
    "auth.set_access_token(access_token, access_token_secret)\n",
    "api = tweepy.API(auth, parser=tweepy.parsers.JSONParser())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>normal_users</th>\n",
       "      <th>fitness_users</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>sbwTweet</td>\n",
       "      <td>relentless084</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Allisonlmoore</td>\n",
       "      <td>fitplusllc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>kristib_t</td>\n",
       "      <td>wchazz</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>omoawo_</td>\n",
       "      <td>QRoberts747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>KelphelpOG</td>\n",
       "      <td>KeynesJohnny</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    normal_users  fitness_users\n",
       "0       sbwTweet  relentless084\n",
       "1  Allisonlmoore     fitplusllc\n",
       "2      kristib_t         wchazz\n",
       "3        omoawo_    QRoberts747\n",
       "4     KelphelpOG   KeynesJohnny"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read in merged dataset \n",
    "file = \"datasets/merged_lists_032118.csv\"\n",
    "\n",
    "df = pd.read_csv(file)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "normal_users = df[\"normal_users\"].tolist()\n",
    "fitness_users = df[\"fitness_users\"].tolist()\n",
    "# normal_users\n",
    "# fitness_users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Set target twitter accounts \n",
    "targetnormal_users = normal_users \n",
    "targetfitness_users = fitness_users\n",
    "\n",
    "# Lists to hold user accounts, tweets, dates, & sentiments\n",
    "user_acct = []\n",
    "tweet_txt = []\n",
    "tweet_dt =[]\n",
    "# Vader lists \n",
    "compound_list = []\n",
    "positive_list = []\n",
    "negative_list = []\n",
    "neutral_list = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# # Loop through all fitness users \n",
    "# for target in targetfitness_users:\n",
    "    \n",
    "#     # Loop through once (20 tweets)\n",
    "#     for x in range(1):\n",
    "        \n",
    "#         # Get tweets for one page for each user (20 tweets)\n",
    "#         public_tweets = api.user_timeline(target, page=x)\n",
    "        \n",
    "#         # Loop through all tweets\n",
    "#         for tweet in public_tweets:\n",
    "            \n",
    "#             # Run Vader Analysis on each tweet\n",
    "#             results = analyzer.polarity_scores(tweet[\"text\"])\n",
    "#             compound = results[\"compound\"]\n",
    "#             pos = results[\"pos\"]\n",
    "#             neu = results[\"neu\"]\n",
    "#             neg = results[\"neg\"]\n",
    "            \n",
    "#             # Add each value to the appropriate list \n",
    "#             user_acct.append(target)\n",
    "#             tweet_txt.append(tweet[\"text\"])\n",
    "#             tweet_dt.append(tweet[\"created_at\"])\n",
    "            \n",
    "#             compound_list.append(compound)\n",
    "#             positive_list.append(pos)\n",
    "#             negative_list.append(neg)\n",
    "#             neutral_list.append(neu)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Users possibly changed their username or deleted account since fitness usernames were extracted, see error below\n",
    "TweepError: [{'code': 34, 'message': 'Sorry, that page does not exist.'}]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# # Convert tweet timestamps to datetime objects\n",
    "# converted_timestamps = []\n",
    "# for dt in tweet_dt:\n",
    "#     converted_time = datetime.strptime(dt, \"%a %b %d %H:%M:%S %z %Y\")\n",
    "#     converted_timestamps.append(converted_time)\n",
    "    \n",
    "# # Confirm length of list \n",
    "# print(len(converted_timestamps))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tweet count: 7465\n",
    "### Tweet count should have been 10,000 (500 users * 20 tweets); likely changed handle or deleted account."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# # Create dataframe for all accounts and tweets\n",
    "# df_fit = pd.DataFrame({\"Account\":user_acct,\n",
    "#                    \"Tweet Text\":tweet_txt,\n",
    "#                    \"Date\":converted_timestamps,\n",
    "#                    \"Compound\":compound_list,\n",
    "#                    \"Positive\":positive_list,\n",
    "#                    \"Negative\":negative_list,\n",
    "#                    \"Neutral\":neutral_list\n",
    "#                   })\n",
    "# df_fit.head()\n",
    "# # Reorder columns \n",
    "# df_fit2 = df_fit[['Account', 'Date', 'Tweet Text', 'Compound', 'Positive', 'Neutral', 'Negative']]\n",
    "# df_fit2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# #Save df to csv\n",
    "# df_fit2.to_csv(\"datasets/fit_tweets.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# from matplotlib import style\n",
    "# style.use('ggplot')\n",
    "\n",
    "# plt.scatter(range(len(df_fit2[\"Date\"].values)), df_fit2[\"Compound\"], edgecolor=\"black\", color='green', marker=\"o\",\n",
    "#             alpha=0.65, label=\"fitness users\")\n",
    "\n",
    "# # Set title and axis labels\n",
    "# plt.title(\"Sentiment Analysis of Fitness Tweets\")\n",
    "# plt.ylabel(\"Tweet Polarity (Compound Score)\")\n",
    "# plt.xlabel(\"Tweets Ago\")\n",
    "# # plt.legend(bbox_to_anchor=(1, 1),title=\"Media Sources\")\n",
    "# plt.xticks(rotation=\"vertical\")\n",
    "# # plt.xlim(-2,102)\n",
    "# # plt.ylim([-1.05, 1.05])\n",
    "\n",
    "# # Save and show the figure\n",
    "# plt.savefig(\"SentimentAnalysisScatterplot.png\")\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sorry, justlovemyjulia not found. Skipping.\n",
      "Sorry, glennonart not found. Skipping.\n",
      "Sorry, TranslucentKami not found. Skipping.\n",
      "Sorry, dhbsa_ not found. Skipping.\n",
      "Sorry, yvvduaarte not found. Skipping.\n",
      "Sorry, Mennaelzohairy_ not found. Skipping.\n",
      "Sorry, HeyChelseaTroy not found. Skipping.\n",
      "Sorry, justrough33 not found. Skipping.\n",
      "Sorry, estrellaibccsc1 not found. Skipping.\n",
      "Sorry, DaisyVelarde3 not found. Skipping.\n",
      "Sorry, brooker_steph not found. Skipping.\n",
      "Sorry, uniqueANGELIN not found. Skipping.\n",
      "Sorry, EpicTakeDubs not found. Skipping.\n",
      "Sorry, JasroopM not found. Skipping.\n",
      "Sorry, HGI4CY not found. Skipping.\n",
      "Sorry, mksharma4269 not found. Skipping.\n",
      "Sorry, raissafrd not found. Skipping.\n",
      "Sorry, sivadasn not found. Skipping.\n",
      "Sorry, leap404 not found. Skipping.\n",
      "Sorry, broaddayjay___ not found. Skipping.\n",
      "Sorry, Frxnchx_Park95 not found. Skipping.\n",
      "Sorry, Jenyshadow9386 not found. Skipping.\n",
      "Sorry, kingdanieeel not found. Skipping.\n",
      "Sorry, Baby71cakes not found. Skipping.\n",
      "Sorry, SafwanYP not found. Skipping.\n",
      "Sorry, OfficialPJ14 not found. Skipping.\n",
      "Sorry, IrlaneAndre not found. Skipping.\n",
      "Sorry, lolas_waterwell not found. Skipping.\n",
      "Sorry, wine_goblin not found. Skipping.\n",
      "Sorry, LaurenHunter201 not found. Skipping.\n",
      "Sorry, KendxllSNG not found. Skipping.\n",
      "Sorry, jhughes_8 not found. Skipping.\n",
      "Sorry, ShabdaGyawali not found. Skipping.\n",
      "Sorry, natsumi_fern not found. Skipping.\n",
      "Sorry, IraisVergaraSo3 not found. Skipping.\n",
      "Sorry, lavish2302 not found. Skipping.\n",
      "Sorry, bmcfadded not found. Skipping.\n",
      "Sorry, JeffersonBennie not found. Skipping.\n",
      "Sorry, __JeffChang not found. Skipping.\n",
      "Sorry, nurqiamianis not found. Skipping.\n",
      "Sorry, eujaevivas not found. Skipping.\n",
      "Sorry, delaneygwesig not found. Skipping.\n",
      "Sorry, Sharovatik not found. Skipping.\n",
      "Sorry, killgncd not found. Skipping.\n",
      "Sorry, atulxshfri not found. Skipping.\n",
      "Sorry, waitforaliens not found. Skipping.\n",
      "Sorry, AWAKESEOKJlN not found. Skipping.\n",
      "Sorry, bremoonprincess not found. Skipping.\n",
      "Sorry, MisssYumiko not found. Skipping.\n",
      "Sorry, annalise_webb not found. Skipping.\n",
      "Sorry, bianhsj not found. Skipping.\n",
      "Sorry, mishelstarr not found. Skipping.\n",
      "Sorry, JGCii not found. Skipping.\n",
      "Sorry, cachelrumbo not found. Skipping.\n",
      "Sorry, _ALISONORTIZ_ not found. Skipping.\n",
      "Sorry, MagnarHu not found. Skipping.\n",
      "Sorry, taylorakre not found. Skipping.\n",
      "Sorry, ShaughnMcArthur not found. Skipping.\n",
      "Sorry, CanttGuard3 not found. Skipping.\n",
      "Sorry, FTBAlwaysaware not found. Skipping.\n",
      "Sorry, Stewgc64 not found. Skipping.\n",
      "Sorry, terrycruss not found. Skipping.\n",
      "Sorry, Gambino21H8 not found. Skipping.\n",
      "Sorry, leexilovesyou not found. Skipping.\n",
      "Sorry, kymbeolli not found. Skipping.\n",
      "Sorry, macker99 not found. Skipping.\n",
      "Sorry, 18Larrie not found. Skipping.\n",
      "Sorry, BlakeKamea not found. Skipping.\n",
      "Sorry, dlemke26 not found. Skipping.\n",
      "Sorry, 3dxts_by_m3 not found. Skipping.\n",
      "Sorry, Spaldingrob not found. Skipping.\n",
      "Sorry, abdelrahman319 not found. Skipping.\n",
      "Sorry, fletch_t35 not found. Skipping.\n",
      "Sorry, SamBarbee1 not found. Skipping.\n",
      "Sorry, realwrestlingau not found. Skipping.\n",
      "Sorry, Shadowhunt2017 not found. Skipping.\n",
      "Sorry, MJD1953 not found. Skipping.\n",
      "Sorry, Boo_Do_Hazz28 not found. Skipping.\n",
      "Sorry, kbdonnally not found. Skipping.\n",
      "Sorry, Tayluhh_Mariee not found. Skipping.\n",
      "Sorry, cvpiik not found. Skipping.\n",
      "Sorry, VictoriaMarinaa not found. Skipping.\n",
      "Sorry, Sblaz3 not found. Skipping.\n",
      "Sorry, abolistik34 not found. Skipping.\n",
      "Sorry, Imperial_Olord not found. Skipping.\n",
      "Sorry, heidi_horner_ not found. Skipping.\n",
      "Sorry, larryas89 not found. Skipping.\n",
      "Sorry, ms_amrit not found. Skipping.\n",
      "Sorry, TheLeadersHeart not found. Skipping.\n",
      "Sorry, _ashleyttran not found. Skipping.\n",
      "Sorry, sumitdezignme not found. Skipping.\n",
      "Sorry, allmantodd not found. Skipping.\n",
      "Sorry, KieraMolloy1 not found. Skipping.\n",
      "Sorry, Meganrosswv not found. Skipping.\n",
      "Sorry, caitlynnleahh not found. Skipping.\n",
      "Sorry, that1paisa not found. Skipping.\n",
      "Sorry, AmnaAsad19 not found. Skipping.\n",
      "Sorry, da_danp not found. Skipping.\n",
      "Sorry, MarbellaUnicorn not found. Skipping.\n",
      "Sorry, suz4314 not found. Skipping.\n",
      "Sorry, RycePark not found. Skipping.\n",
      "Sorry, ChimChi35933477 not found. Skipping.\n",
      "Sorry, Bellajean05 not found. Skipping.\n",
      "Sorry, _heyitsmaddy not found. Skipping.\n"
     ]
    }
   ],
   "source": [
    "# Loop through all normal users \n",
    "for target in targetnormal_users:\n",
    "    \n",
    "    # Loop through once (20 tweets)\n",
    "\n",
    "    # Get tweets for one page for each user (20 tweets)\n",
    "    try:\n",
    "        public_tweets = api.user_timeline(target)\n",
    "\n",
    "        # Loop through all tweets\n",
    "        for tweet in public_tweets:\n",
    "\n",
    "            # Run Vader Analysis on each tweet\n",
    "            results = analyzer.polarity_scores(tweet[\"text\"])\n",
    "            compound = results[\"compound\"]\n",
    "            pos = results[\"pos\"]\n",
    "            neu = results[\"neu\"]\n",
    "            neg = results[\"neg\"]\n",
    "\n",
    "            # Add each value to the appropriate list \n",
    "            user_acct.append(target)\n",
    "            tweet_txt.append(tweet[\"text\"])\n",
    "            tweet_dt.append(tweet[\"created_at\"])\n",
    "\n",
    "            compound_list.append(compound)\n",
    "            positive_list.append(pos)\n",
    "            negative_list.append(neg)\n",
    "            neutral_list.append(neu)\n",
    "    except tweepy.error.TweepError:\n",
    "        print(f'Sorry, {target} not found. Skipping.')\n",
    "        continue"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Users possibly changed their username or deleted account since fitness usernames were extracted, see error below\n",
    "TweepError: [{'code': 34, 'message': 'Sorry, that page does not exist.'}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7867\n"
     ]
    }
   ],
   "source": [
    "# Convert tweet timestamps to datetime objects\n",
    "converted_timestamps = []\n",
    "for dt in tweet_dt:\n",
    "    converted_time = datetime.strptime(dt, \"%a %b %d %H:%M:%S %z %Y\")\n",
    "    converted_timestamps.append(converted_time)\n",
    "    \n",
    "# Confirm length of list \n",
    "print(len(converted_timestamps))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tweet count: 200\n",
    "### why?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dataframe for all accounts and tweets\n",
    "df_norm = pd.DataFrame({\"Account\":user_acct,\n",
    "                   \"Tweet Text\":tweet_txt,\n",
    "                   \"Date\":converted_timestamps,\n",
    "                   \"Compound\":compound_list,\n",
    "                   \"Positive\":positive_list,\n",
    "                   \"Negative\":negative_list,\n",
    "                   \"Neutral\":neutral_list\n",
    "                  })\n",
    "df_norm.head()\n",
    "# Reorder columns \n",
    "df_norm2 = df_norm[['Account', 'Date', 'Tweet Text', 'Compound', 'Positive', 'Neutral', 'Negative']]\n",
    "df_norm2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Save df to csv\n",
    "df_norm2.to_csv(\"datasets/norm_tweets1.csv\",encoding='utf-8',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import style\n",
    "style.use('ggplot')\n",
    "\n",
    "plt.scatter(range(len(df_norm2[\"Date\"].values)), df_norm2[\"Compound\"], edgecolor=\"black\", color='dodgerblue', marker=\"o\",\n",
    "            alpha=0.65, label=\"normal users\")\n",
    "\n",
    "# Set title and axis labels\n",
    "plt.title(\"Sentiment Analysis of Normal Tweets\")\n",
    "plt.ylabel(\"Tweet Polarity (Compound Score)\")\n",
    "plt.xlabel(\"Tweets\")\n",
    "# plt.legend(bbox_to_anchor=(1, 1),title=\"Media Sources\")\n",
    "plt.xticks(rotation=\"vertical\")\n",
    "# plt.xlim(-2,102)\n",
    "# plt.ylim([-1.05, 1.05])\n",
    "\n",
    "# Save and show the figure\n",
    "plt.savefig(\"SentimentAnalysisScatterplot_norm.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
